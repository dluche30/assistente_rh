# app_rh_assistente.py
import streamlit as st
from openai import OpenAI
import os, json, io, logging
from datetime import datetime
import pandas as pd
import fitz                             # PyMuPDF
import gspread
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload, MediaIoBaseUpload

# ----------------------------------------------------------------------
# CONFIGURA√á√ïES GERAIS
# ----------------------------------------------------------------------
st.set_page_config(page_title="Assistente Virtual de Recrutamento", page_icon="ü§ñ")

# ‚¨áÔ∏è  logging b√°sico (aparecer√° no terminal ou em Cloud Run, etc.)
logging.basicConfig(level=logging.INFO, format="%(levelname)s %(message)s")

# -------- OPENAI --------
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# -------- GOOGLE --------
SCOPES = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive"
]
creds = service_account.Credentials.from_service_account_info(
    json.loads(st.secrets["GOOGLE_SERVICE_ACCOUNT_JSON"]),
    scopes=SCOPES
)
gc = gspread.authorize(creds)
sheet = gc.open("chat_logs_rh").sheet1
drive_service = build("drive", "v3", credentials=creds)

FOLDER_ID = "1oMSIeD00E3amFjTX4zUW8LfJFctxOMn4"

# ----------------------------------------------------------------------
# FUN√á√ïES UTILIT√ÅRIAS
# ----------------------------------------------------------------------
@st.cache_data(show_spinner=False)
def extrair_texto_pdf(file_bytes: bytes) -> str:
    texto = ""
    with fitz.open(stream=file_bytes, filetype="pdf") as doc:
        for pagina in doc:
            texto += pagina.get_text()
    return texto

def listar_curriculos_drive():
    res = drive_service.files().list(
        q=f"'{FOLDER_ID}' in parents and mimeType='application/pdf'",
        fields="files(id, name)"
    ).execute()
    return res.get("files", [])

def baixar_curriculo(file_id: str) -> bytes:
    request = drive_service.files().get_media(fileId=file_id)
    file_data = io.BytesIO()
    downloader = MediaIoBaseDownload(file_data, request)
    done = False
    while not done:
        _, done = downloader.next_chunk()
    file_data.seek(0)
    return file_data.read()

def ler_curriculo_drive(file_id: str, nome: str):
    pdf_bytes = baixar_curriculo(file_id)
    texto = extrair_texto_pdf(pdf_bytes)
    st.session_state.texto_curriculos += f"\n\n===== {nome} =====\n{texto}"

def upload_curriculo(file_uploaded):
    meta = {"name": file_uploaded.name, "parents": [FOLDER_ID]}
    media = MediaIoBaseUpload(file_uploaded, mimetype="application/pdf")
    uploaded = drive_service.files().create(
        body=meta, media_body=media, fields="id, webViewLink"
    ).execute()
    st.success(
        f"Curr√≠culo **{file_uploaded.name}** enviado com sucesso! "
        f"[Abrir no Drive]({uploaded['webViewLink']})"
    )

def atualizar_prompt():
    """Reconstr√≥i a primeira mensagem do sistema com vagas + curr√≠culos."""
    preambulo = (
        "Voc√™ √© um assistente de RH. Ajude na an√°lise de curr√≠culos.\n\n"
        f"Informa√ß√µes dos curr√≠culos analisados:\n{st.session_state.texto_curriculos}\n\n"
        f"As vagas dispon√≠veis s√£o:\n{st.session_state.texto_vagas}"
    )
    st.session_state.mensagens[0]["content"] = preambulo

def mostrar_historico():
    """Renderiza o chat do segundo elemento em diante (0 = system)."""
    for msg in st.session_state.mensagens[1:]:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

def processar_entrada(prompt_usuario: str):
    """Anexa a pergunta, chama a API, salva resposta e for√ßa rerun."""
    st.session_state.mensagens.append({"role": "user", "content": prompt_usuario})
    atualizar_prompt()

    try:
        resposta = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=st.session_state.mensagens
        )
        conteudo = resposta.choices[0].message.content
        st.session_state.mensagens.append({"role": "assistant", "content": conteudo})

        # LOG planilha Google Sheets
        sheet.append_row([
            datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            st.session_state.usuario_nome,
            prompt_usuario,
            conteudo,
        ])

    except Exception as e:
        logging.error("Erro na chamada ao modelo: %s", e, exc_info=True)
        st.session_state.mensagens.append({
            "role": "assistant",
            "content": "Desculpe, ocorreu um erro ao processar sua solicita√ß√£o."
        })

    st.rerun()   # evita duplica√ß√£o de mensagens e simplifica fluxo

# ----------------------------------------------------------------------
# ESTADO INICIAL
# ----------------------------------------------------------------------
st.session_state.setdefault("texto_curriculos", "")
st.session_state.setdefault("texto_vagas", "")
if "mensagens" not in st.session_state:
    st.session_state.mensagens = [{"role": "system", "content": ""}]
    atualizar_prompt()


def gerar_tabela_aderencia(curriculos_texto, vagas_texto):
    prompt = f"""
Voc√™ √© um assistente de recrutamento. Com base nas vagas abaixo e nos curr√≠culos fornecidos, gere uma tabela que mostre a ader√™ncia de cada candidato para cada vaga.

- Liste os nomes dos candidatos nas linhas.
- Liste as vagas nas colunas.
- Utilize crit√©rios como: correspond√™ncia de compet√™ncias, experi√™ncias, forma√ß√µes e requisitos da vaga.

Apresente os dados em formato de tabela, atribuindo um n√≠vel de ader√™ncia (ex.: Alto, M√©dio, Baixo) ou uma pontua√ß√£o de 0 a 100, se poss√≠vel.

Curr√≠culos analisados:
{curriculos_texto}

Vagas dispon√≠veis:
{vagas_texto}
"""

    resposta = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": st.session_state.mensagens[0]["content"]},
            {"role": "user", "content": prompt}
        ]
    )

    return resposta.choices[0].message.content



import time
import openai

def gerar_tabela_aderencia(curriculos_texto, vagas_texto, modelo_ia):
    prompt = f"""
Voc√™ √© um assistente de recrutamento. Com base nas vagas abaixo e nos curr√≠culos fornecidos, gere uma tabela que mostre a ader√™ncia de cada candidato para cada vaga.

- Liste os nomes dos candidatos nas linhas.
- Liste as vagas nas colunas.
- Utilize crit√©rios como: correspond√™ncia de compet√™ncias, experi√™ncias, forma√ß√µes e requisitos da vaga.

Apresente os dados em formato de tabela, atribuindo um n√≠vel de ader√™ncia (ex.: Alto, M√©dio, Baixo) ou uma pontua√ß√£o de 0 a 100, se poss√≠vel.

Curr√≠culos analisados:
{curriculos_texto}

Vagas dispon√≠veis:
{vagas_texto}
"""

    tentativas = 5
    for tentativa in range(tentativas):
        try:
            resposta = client.chat.completions.create(
                model=modelo_ia,
                messages=[
                    {"role": "system", "content": st.session_state.mensagens[0]["content"]},
                    {"role": "user", "content": prompt}
                ]
            )
            return resposta.choices[0].message.content

        except openai.RateLimitError:
            wait_time = 2 ** tentativa
            st.warning(f"‚ö†Ô∏è Limite atingido. Tentando novamente em {wait_time} segundos...")
            time.sleep(wait_time)

    st.error("‚ùå N√£o foi poss√≠vel gerar a tabela ap√≥s v√°rias tentativas devido ao limite da API.")
    return "Erro: Limite da API OpenAI atingido."


# ----------------------------------------------------------------------
# INTERFACE
# ----------------------------------------------------------------------
st.image("logo_unesp.png", width=300)
st.title("Assistente Virtual de Recrutamento")

# ---- Nome do usu√°rio ----
usuario_nome = st.text_input("Digite seu nome completo:", key="nome_usuario_input")
if not usuario_nome:
    st.warning("Por favor, preencha seu nome para iniciar.")
    st.stop()
st.session_state.usuario_nome = usuario_nome

# ---- Carregar vagas ----
try:
    vagas_df = pd.read_csv("vagas_exemplo.csv")
    st.subheader("üìë Vagas dispon√≠veis")
    st.dataframe(vagas_df)
    st.session_state.texto_vagas = vagas_df.to_string(index=False)
except Exception:
    st.warning("Arquivo de vagas n√£o encontrado.")
    st.session_state.texto_vagas = ""


st.subheader("‚öôÔ∏è Configura√ß√µes do Assistente")
modelo_ia = st.selectbox(
    "Escolha o modelo de IA para an√°lise:",
    options=["gpt-4", "gpt-3.5-turbo"],
    index=1
)


# ---- HIST√ìRICO DO CHAT (antes do input) ----
st.divider()
mostrar_historico()
st.divider()

# ---- Upload de curr√≠culo ----
with st.expander("üì§ Enviar novo curr√≠culo (PDF) para o Google Drive"):
    file_uploaded = st.file_uploader("Selecione o arquivo", type=["pdf"])
    if file_uploaded and st.button("üöÄ Enviar"):
        upload_curriculo(file_uploaded)

# ---- Ler curr√≠culos ----
st.subheader("üìÑ Curr√≠culos no Google Drive")
curriculos = listar_curriculos_drive()
nomes = [c["name"] for c in curriculos]
selecionados = st.multiselect("Selecione curr√≠culos para an√°lise:", nomes)

col_le, col_to = st.columns(2)
with col_le:
    if st.button("üîç Ler curr√≠culos selecionados"):
        if not selecionados:
            st.warning("Selecione pelo menos um curr√≠culo.")
        else:
            for nome in selecionados:
                file_id = next(c["id"] for c in curriculos if c["name"] == nome)
                ler_curriculo_drive(file_id, nome)
            atualizar_prompt()
            st.success("Curr√≠culos lidos e armazenados na mem√≥ria!")
with col_to:
    if st.button("üì• Ler TODOS os curr√≠culos"):
        for c in curriculos:
            ler_curriculo_drive(c["id"], c["name"])
        atualizar_prompt()
        st.success("Todos os curr√≠culos lidos!")


# ---- Gera√ß√£o de Tabela de Ader√™ncia ----
st.subheader("üìä An√°lise de Ader√™ncia Curr√≠culo vs Vagas")
if st.button("üîç Gerar Tabela de Ader√™ncia"):

    if not st.session_state.texto_curriculos or not st.session_state.texto_vagas:
        st.warning("Por favor, carregue curr√≠culos e vagas antes de gerar a an√°lise.")
    else:
        with st.spinner("Analisando curr√≠culos e vagas..."):
            tabela = gerar_tabela_aderencia(
                st.session_state.texto_curriculos,
                st.session_state.texto_vagas
            )
            st.subheader("üîç Resultado da An√°lise de Ader√™ncia")
            st.markdown(tabela)



# ---- Gera√ß√£o de Tabela de Ader√™ncia ----
st.subheader("üìä An√°lise de Ader√™ncia Curr√≠culo vs Vagas")
if st.button("üîç Gerar Tabela de Ader√™ncia"):

    if not st.session_state.texto_curriculos or not st.session_state.texto_vagas:
        st.warning("Por favor, carregue curr√≠culos e vagas antes de gerar a an√°lise.")
    else:
        with st.spinner("Analisando curr√≠culos e vagas..."):
            tabela = gerar_tabela_aderencia(
                st.session_state.texto_curriculos,
                st.session_state.texto_vagas,
                modelo_ia
            )
            st.subheader("üîç Resultado da An√°lise de Ader√™ncia")
            st.markdown(tabela)


# ---- Campo de entrada do usu√°rio ----
prompt_usuario = st.chat_input("Digite sua mensagem para o assistente...")
if prompt_usuario:
    processar_entrada(prompt_usuario)
