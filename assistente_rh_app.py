import streamlit as st
import openai
import os
from dotenv import load_dotenv

# Carregar chave da OpenAI
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

st.set_page_config(page_title="Assistente RH com IA", layout="wide")
st.title("ü§ñ Assistente Virtual de Recrutamento")

# Inicializar hist√≥rico da conversa
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Mostrar hist√≥rico
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Entrada do usu√°rio
prompt = st.chat_input("Descreva seu perfil ou fa√ßa uma pergunta sobre recrutamento...")

if prompt:
    st.chat_message("user").markdown(prompt)
    st.session_state.chat_history.append({"role": "user", "content": prompt})

    # Pre√¢mbulo (instru√ß√µes fixas para o modelo)
    system_message = {
        "role": "system",
        "content": (
            "Voc√™ √© um assistente de RH especializado em triagem de curr√≠culos e orienta√ß√£o profissional. "
            "Analise perfis profissionais com base em compet√™ncias, experi√™ncias e alinhamento com √°reas espec√≠ficas. "
            "Evite julgamentos definitivos, incentive o autoconhecimento e ofere√ßa feedback construtivo. "
            "Seja cordial e objetivo. Em caso de dados insuficientes, pe√ßa mais informa√ß√µes ao usu√°rio."
        )
    }

    # Hist√≥rico para envio ao modelo
    messages = [system_message] + st.session_state.chat_history

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=messages
        )
        reply = response["choices"][0]["message"]["content"]
        st.chat_message("assistant").markdown(reply)
        st.session_state.chat_history.append({"role": "assistant", "content": reply})

    except Exception as e:
        st.error(f"Ocorreu um erro: {e}")
